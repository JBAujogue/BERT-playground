{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X4cRE8IbIrIV"
   },
   "source": [
    "<div style=\"font-variant: small-caps; \n",
    "      font-weight: normal; \n",
    "      font-size: 35px; \n",
    "      text-align: center; \n",
    "      padding: 15px; \n",
    "      margin: 10px;\">\n",
    "      Language Modeling\n",
    "  </div> \n",
    "  \n",
    "<div style=\"\n",
    "      font-weight: normal; \n",
    "      font-size: 25px; \n",
    "      text-align: center; \n",
    "      padding: 15px; \n",
    "      margin: 10px;\">\n",
    "      Albert Small on custom task - Clinical Trials CTTI\n",
    "  </div> \n",
    "\n",
    "\n",
    "  <div style=\"\n",
    "      font-size: 15px; \n",
    "      line-height: 12px; \n",
    "      text-align: center; \n",
    "      padding: 15px; \n",
    "      margin: 10px;\">\n",
    "  Jean-baptiste AUJOGUE\n",
    "  </div> \n",
    "\n",
    "  \n",
    "  <div style=\" float:right; \n",
    "      font-size: 12px; \n",
    "      line-height: 12px; \n",
    "  padding: 10px 15px 8px;\">\n",
    "  December 2022\n",
    "  </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"TOC\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Table Of Content\n",
    "\n",
    "1. [Dataset](#data) <br>\n",
    "2. [ALBERT finetuning](#albert) <br>\n",
    "3. [Inference](#inference) <br>\n",
    "\n",
    "\n",
    "\n",
    "#### Reference\n",
    "\n",
    "- Hugginface full list of [tutorial notebooks](https://github.com/huggingface/transformers/tree/main/notebooks) (see also [here](https://huggingface.co/docs/transformers/main/notebooks#pytorch-examples))\n",
    "- Huggingface full list of [training scripts](https://github.com/huggingface/transformers/tree/main/examples/pytorch)\n",
    "- Huggingface [tutorial notebook](https://github.com/huggingface/notebooks/blob/main/examples/language_modeling_from_scratch.ipynb) on language models\n",
    "- Huggingface [course](https://huggingface.co/course/chapter7/3?fw=tf) on language models\n",
    "- Huggingface [training script](https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py) on language models\n",
    "- Albert [original training protocol](https://github.com/google-research/albert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jb\\miniconda3\\envs\\transformers_nlp\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from itertools import chain\n",
    "\n",
    "import pandas as pd\n",
    "from datasets import (\n",
    "    Dataset, \n",
    "    Features, \n",
    "    Value,\n",
    "    load_from_disk,\n",
    ")\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForMaskedLM, \n",
    "    TrainingArguments, \n",
    "    Trainer,\n",
    "    pipeline,\n",
    "    set_seed,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformers settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.22.2'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformers.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make training deterministic\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom paths & imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_repo = os.path.dirname(os.getcwd())\n",
    "path_to_data = os.path.join(path_to_repo, 'datasets', 'clinical trials CTTI')\n",
    "path_to_save = os.path.join(path_to_repo, 'models', 'mlm')\n",
    "path_to_src  = os.path.join(path_to_repo, 'src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, path_to_src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bertools.tasks.mlm import CustomDataCollatorForLanguageModeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'clinical-trials-ctti'\n",
    "base_model_name = \"albert-small-ctti\"\n",
    "final_model_name = \"albert-small-dlm-ctti\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"data\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "whPRbBNbIrIl"
   },
   "source": [
    "# 1. Dataset\n",
    "\n",
    "[Table of content](#TOC)\n",
    "\n",
    "We generate a collection of instances of the `datasets.Dataset` class. \n",
    "\n",
    "Note that these are different from the fairly generic `torch.utils.data.Dataset` class. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Load Clinical Trials corpus\n",
    "\n",
    "[Table of content](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_empty_lines(examples):\n",
    "    examples['text'] = [\n",
    "        t for t in examples['text'] if len(t) > 0 and not t.isspace()\n",
    "    ]\n",
    "    return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(430108, 7)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trials = pd.read_csv(os.path.join(path_to_data, '{}.tsv'.format(dataset_name)), sep = \"\\t\")\n",
    "df_trials = df_trials.fillna('')\n",
    "df_trials.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1041969"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = df_trials[['Summary', 'Description', 'IE_criteria']].values.tolist()\n",
    "texts = [t.strip() for ts in texts for t in ts if len(t.strip())>=50]\n",
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.from_dict({'text': texts}, features = Features({'text': Value(dtype = 'string')}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.map(remove_empty_lines, batched = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YVx71GdAIrJH"
   },
   "source": [
    "## 1.2 Build Clinical-Albert-small tokenizer\n",
    "\n",
    "[Table of content](#TOC)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_iterator(dataset, batch_size = 512):\n",
    "    for i in range(0, len(dataset), batch_size):\n",
    "        yield dataset[i: i + batch_size]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(os.path.join(path_to_save, base_model_name, 'tokenizer'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YVx71GdAIrJH"
   },
   "source": [
    "## 1.3 Tokenize corpus\n",
    "\n",
    "[Table of content](#TOC)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "DDtsaJeVIrJT",
    "outputId": "aa4734bf-4ef5-4437-9948-2c16363da719"
   },
   "outputs": [],
   "source": [
    "tokenized_dataset = dataset.map(\n",
    "    lambda examples: tokenizer(examples[\"text\"], return_special_tokens_mask = True), \n",
    "    batched = True, \n",
    "    remove_columns = [\"text\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By contrast to the generic BIO annotated data, this new data depends on the tokenizer, and is therefore _model-specific_.\n",
    "\n",
    "_Note_: the argument `remove_columns = [\"text\"]` is mandatory, in order to have each item of the dataset have same length."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YVx71GdAIrJH"
   },
   "source": [
    "## 1.4 Form blocks of constant length\n",
    "\n",
    "[Table of content](#TOC)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_texts(examples, block_size):\n",
    "    # Concatenate all texts.\n",
    "    keys = [k for k in examples.keys() if k != 'text']\n",
    "    concatenated_examples = {k: list(chain(*examples[k])) for k in examples.keys()}\n",
    "    total_length = len(concatenated_examples[keys[0]])\n",
    "    \n",
    "    # We drop the small remainder, we could add padding if the model supported it instead of this drop, you can\n",
    "    # customize this part to your needs.\n",
    "    if total_length >= block_size:\n",
    "        total_length = (total_length // block_size) * block_size\n",
    "    \n",
    "    # Split by chunks of max_len.\n",
    "    result = {\n",
    "        k: [t[i : i+block_size] for i in range(0, total_length, block_size)]\n",
    "        for k, t in concatenated_examples.items()\n",
    "    }\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlm_dataset = tokenized_dataset.map(\n",
    "#    lambda examples: group_texts(examples, block_size = 512), batched = True\n",
    "# )\n",
    "# mlm_dataset.save_to_disk(os.path.join(path_to_data, 'tmp', dataset_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "421077"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_dataset = load_from_disk(os.path.join(path_to_data, 'tmp', dataset_name))\n",
    "len(lm_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(tokenizer.decode(lm_dataset[0][\"input_ids\"]), tokenizer.decode(lm_dataset[0][\"labels\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(lm_dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"albert\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n9qywopnIrJH"
   },
   "source": [
    "# 2. ALBERT-small training\n",
    "\n",
    "[Table of content](#TOC)\n",
    "\n",
    "#### Tested combinations\n",
    "\n",
    "- 1.4M parameter model: converges fast (1 epoch) towards confusion score~=2.2. Issue : Finetuning of NER on Chia hard, stuck to high training error and/or provides evaluation errors\n",
    "- 3.5M parameter model: gets stuck at confusion score~=5.9. Training args : block_size = 512, bs = 16, lr = 1e-4, grad_acc_step = 4, warmup_step = 500, num_layer = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "545PP3o8IrJV"
   },
   "source": [
    "## 2.1 Build Clinical-Albert-small model\n",
    "\n",
    "[Table of content](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = AutoModelForMaskedLM.from_pretrained(os.path.join(path_to_save, base_model_name, 'model'), device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2584584"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.num_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Model training\n",
    "\n",
    "[Table of content](#TOC)\n",
    "\n",
    "`Albert-vase-v2` training parameters as provided in https://github.com/google-research/albert/blob/master/run_pretraining.py : \n",
    "- max_predictions_per_seq = `20`\n",
    "- train_batch_size = `4096`\n",
    "- optimizer = `\"lamb\"`\n",
    "- learning_rate = `0.00176`\n",
    "- poly_power = `1.0`\n",
    "- num_train_steps = `125000`\n",
    "- num_warmup_steps = `3125`\n",
    "- start_warmup_step = `0`\n",
    "- iterations_per_loop = `1000`\n",
    "\n",
    "The original optimizer is `lamb`, which was designed for very large batch size, see the [Lamb paper](https://arxiv.org/pdf/1904.00962.pdf), but we use here the default [AdamW](https://huggingface.co/docs/transformers/main_classes/optimizer_schedules#transformers.AdamW) optimizer with [linear learning rate decay](https://huggingface.co/docs/transformers/v4.23.1/en/main_classes/optimizer_schedules#transformers.get_linear_schedule_with_warmup), as specified in the [Trainer class documentation](https://huggingface.co/docs/transformers/main_classes/trainer#transformers.Trainer.optimizers). See the [AdamW paper](https://arxiv.org/pdf/1711.05101.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "    output_dir = os.path.join(path_to_save, '_checkpoints'),\n",
    "    evaluation_strategy = \"no\",\n",
    "    learning_rate = 5e-4,\n",
    "    num_train_epochs = 1,\n",
    "    warmup_steps = 1500,\n",
    "    gradient_accumulation_steps = 1,\n",
    "    per_device_train_batch_size = batch_size,\n",
    "    per_device_eval_batch_size = batch_size,\n",
    "    save_strategy = 'no',\n",
    "    logging_steps = 100,\n",
    "    seed = 42,\n",
    "    data_seed = 23,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.2000, 0.2000, 0.2000, 0.4000])\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    data_collator = CustomDataCollatorForLanguageModeling(\n",
    "        tokenizer = tokenizer, \n",
    "        task_proportions = (2, 2, 2, 4),\n",
    "    ),\n",
    "    train_dataset = lm_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some remarks:\n",
    "\n",
    "- The `data_collator` is the object used to batch elements of the training & evaluation datasets.\n",
    "- The `tokenizer` is provided in order to automatically pad the inputs to the maximum length when batching inputs, and to have it saved along the model, which makes it easier to rerun an interrupted training or reuse the fine-tuned model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in C:\\Users\\jb\\Desktop\\NLP\\Internal - Transformers for NLP\\saves\\MLM\\clinical-trials-albert-small\\model\\config.json\n",
      "Model weights saved in C:\\Users\\jb\\Desktop\\NLP\\Internal - Transformers for NLP\\saves\\MLM\\clinical-trials-albert-small\\model\\pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "model.save_pretrained(os.path.join(path_to_save, final_model_name, 'model'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"inference\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Inference\n",
    "\n",
    "[Table of content](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(os.path.join(path_to_save, final_model_name, 'tokenizer'))\n",
    "model = AutoModelForMaskedLM.from_pretrained(os.path.join(path_to_save, final_model_name, 'model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlm = pipeline(\n",
    "    task = 'fill-mask', \n",
    "    model = model, \n",
    "    tokenizer = tokenizer,\n",
    "    framework = 'pt',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'score': 0.2646515965461731,\n",
       "   'token': 6,\n",
       "   'token_str': 'the',\n",
       "   'sequence': '[CLS] polyneuropathy of other causes, including but not limited to the demyelinating neuropathies,[MASK] secondary to infection or systemic[MASK], diabetic neuropathy, drug- or toxin-induced neuropathies, multifocal motor[MASK], monoclonal gammopathy of uncertain significance, lumbosacral radiculoplexus neuropathy, pure sensory cidp and acquired demyelinating symmetric (dads) neuropathy (also known as distal cidp).[SEP]'},\n",
       "  {'score': 0.07012559473514557,\n",
       "   'token': 105,\n",
       "   'token_str': 'other',\n",
       "   'sequence': '[CLS] polyneuropathy of other causes, including but not limited to other demyelinating neuropathies,[MASK] secondary to infection or systemic[MASK], diabetic neuropathy, drug- or toxin-induced neuropathies, multifocal motor[MASK], monoclonal gammopathy of uncertain significance, lumbosacral radiculoplexus neuropathy, pure sensory cidp and acquired demyelinating symmetric (dads) neuropathy (also known as distal cidp).[SEP]'},\n",
       "  {'score': 0.0340738408267498,\n",
       "   'token': 130,\n",
       "   'token_str': 'any',\n",
       "   'sequence': '[CLS] polyneuropathy of other causes, including but not limited to any demyelinating neuropathies,[MASK] secondary to infection or systemic[MASK], diabetic neuropathy, drug- or toxin-induced neuropathies, multifocal motor[MASK], monoclonal gammopathy of uncertain significance, lumbosacral radiculoplexus neuropathy, pure sensory cidp and acquired demyelinating symmetric (dads) neuropathy (also known as distal cidp).[SEP]'},\n",
       "  {'score': 0.0327921099960804,\n",
       "   'token': 373,\n",
       "   'token_str': 'its',\n",
       "   'sequence': '[CLS] polyneuropathy of other causes, including but not limited to its demyelinating neuropathies,[MASK] secondary to infection or systemic[MASK], diabetic neuropathy, drug- or toxin-induced neuropathies, multifocal motor[MASK], monoclonal gammopathy of uncertain significance, lumbosacral radiculoplexus neuropathy, pure sensory cidp and acquired demyelinating symmetric (dads) neuropathy (also known as distal cidp).[SEP]'},\n",
       "  {'score': 0.017034238204360008,\n",
       "   'token': 10,\n",
       "   'token_str': ',',\n",
       "   'sequence': '[CLS] polyneuropathy of other causes, including but not limited to, demyelinating neuropathies,[MASK] secondary to infection or systemic[MASK], diabetic neuropathy, drug- or toxin-induced neuropathies, multifocal motor[MASK], monoclonal gammopathy of uncertain significance, lumbosacral radiculoplexus neuropathy, pure sensory cidp and acquired demyelinating symmetric (dads) neuropathy (also known as distal cidp).[SEP]'}],\n",
       " [{'score': 0.2568303942680359,\n",
       "   'token': 27,\n",
       "   'token_str': 'or',\n",
       "   'sequence': '[CLS] polyneuropathy of other causes, including but not limited to[MASK] demyelinating neuropathies, or secondary to infection or systemic[MASK], diabetic neuropathy, drug- or toxin-induced neuropathies, multifocal motor[MASK], monoclonal gammopathy of uncertain significance, lumbosacral radiculoplexus neuropathy, pure sensory cidp and acquired demyelinating symmetric (dads) neuropathy (also known as distal cidp).[SEP]'},\n",
       "  {'score': 0.18904247879981995,\n",
       "   'token': 12,\n",
       "   'token_str': 'and',\n",
       "   'sequence': '[CLS] polyneuropathy of other causes, including but not limited to[MASK] demyelinating neuropathies, and secondary to infection or systemic[MASK], diabetic neuropathy, drug- or toxin-induced neuropathies, multifocal motor[MASK], monoclonal gammopathy of uncertain significance, lumbosacral radiculoplexus neuropathy, pure sensory cidp and acquired demyelinating symmetric (dads) neuropathy (also known as distal cidp).[SEP]'},\n",
       "  {'score': 0.06661460548639297,\n",
       "   'token': 38,\n",
       "   'token_str': 'as',\n",
       "   'sequence': '[CLS] polyneuropathy of other causes, including but not limited to[MASK] demyelinating neuropathies, as secondary to infection or systemic[MASK], diabetic neuropathy, drug- or toxin-induced neuropathies, multifocal motor[MASK], monoclonal gammopathy of uncertain significance, lumbosacral radiculoplexus neuropathy, pure sensory cidp and acquired demyelinating symmetric (dads) neuropathy (also known as distal cidp).[SEP]'},\n",
       "  {'score': 0.06018506735563278,\n",
       "   'token': 242,\n",
       "   'token_str': 'but',\n",
       "   'sequence': '[CLS] polyneuropathy of other causes, including but not limited to[MASK] demyelinating neuropathies, but secondary to infection or systemic[MASK], diabetic neuropathy, drug- or toxin-induced neuropathies, multifocal motor[MASK], monoclonal gammopathy of uncertain significance, lumbosacral radiculoplexus neuropathy, pure sensory cidp and acquired demyelinating symmetric (dads) neuropathy (also known as distal cidp).[SEP]'},\n",
       "  {'score': 0.03762368857860565,\n",
       "   'token': 220,\n",
       "   'token_str': 'including',\n",
       "   'sequence': '[CLS] polyneuropathy of other causes, including but not limited to[MASK] demyelinating neuropathies, including secondary to infection or systemic[MASK], diabetic neuropathy, drug- or toxin-induced neuropathies, multifocal motor[MASK], monoclonal gammopathy of uncertain significance, lumbosacral radiculoplexus neuropathy, pure sensory cidp and acquired demyelinating symmetric (dads) neuropathy (also known as distal cidp).[SEP]'}],\n",
       " [{'score': 0.10424439609050751,\n",
       "   'token': 322,\n",
       "   'token_str': 'infection',\n",
       "   'sequence': '[CLS] polyneuropathy of other causes, including but not limited to[MASK] demyelinating neuropathies,[MASK] secondary to infection or systemic infection, diabetic neuropathy, drug- or toxin-induced neuropathies, multifocal motor[MASK], monoclonal gammopathy of uncertain significance, lumbosacral radiculoplexus neuropathy, pure sensory cidp and acquired demyelinating symmetric (dads) neuropathy (also known as distal cidp).[SEP]'},\n",
       "  {'score': 0.08720384538173676,\n",
       "   'token': 2465,\n",
       "   'token_str': 'neuropathy',\n",
       "   'sequence': '[CLS] polyneuropathy of other causes, including but not limited to[MASK] demyelinating neuropathies,[MASK] secondary to infection or systemic neuropathy, diabetic neuropathy, drug- or toxin-induced neuropathies, multifocal motor[MASK], monoclonal gammopathy of uncertain significance, lumbosacral radiculoplexus neuropathy, pure sensory cidp and acquired demyelinating symmetric (dads) neuropathy (also known as distal cidp).[SEP]'},\n",
       "  {'score': 0.08269429951906204,\n",
       "   'token': 598,\n",
       "   'token_str': 'diseases',\n",
       "   'sequence': '[CLS] polyneuropathy of other causes, including but not limited to[MASK] demyelinating neuropathies,[MASK] secondary to infection or systemic diseases, diabetic neuropathy, drug- or toxin-induced neuropathies, multifocal motor[MASK], monoclonal gammopathy of uncertain significance, lumbosacral radiculoplexus neuropathy, pure sensory cidp and acquired demyelinating symmetric (dads) neuropathy (also known as distal cidp).[SEP]'},\n",
       "  {'score': 0.07311790436506271,\n",
       "   'token': 3924,\n",
       "   'token_str': 'lupus',\n",
       "   'sequence': '[CLS] polyneuropathy of other causes, including but not limited to[MASK] demyelinating neuropathies,[MASK] secondary to infection or systemic lupus, diabetic neuropathy, drug- or toxin-induced neuropathies, multifocal motor[MASK], monoclonal gammopathy of uncertain significance, lumbosacral radiculoplexus neuropathy, pure sensory cidp and acquired demyelinating symmetric (dads) neuropathy (also known as distal cidp).[SEP]'},\n",
       "  {'score': 0.05216941237449646,\n",
       "   'token': 909,\n",
       "   'token_str': 'inflammation',\n",
       "   'sequence': '[CLS] polyneuropathy of other causes, including but not limited to[MASK] demyelinating neuropathies,[MASK] secondary to infection or systemic inflammation, diabetic neuropathy, drug- or toxin-induced neuropathies, multifocal motor[MASK], monoclonal gammopathy of uncertain significance, lumbosacral radiculoplexus neuropathy, pure sensory cidp and acquired demyelinating symmetric (dads) neuropathy (also known as distal cidp).[SEP]'}],\n",
       " [{'score': 0.05398792773485184,\n",
       "   'token': 807,\n",
       "   'token_str': 'impairment',\n",
       "   'sequence': '[CLS] polyneuropathy of other causes, including but not limited to[MASK] demyelinating neuropathies,[MASK] secondary to infection or systemic[MASK], diabetic neuropathy, drug- or toxin-induced neuropathies, multifocal motor impairment, monoclonal gammopathy of uncertain significance, lumbosacral radiculoplexus neuropathy, pure sensory cidp and acquired demyelinating symmetric (dads) neuropathy (also known as distal cidp).[SEP]'},\n",
       "  {'score': 0.03970560431480408,\n",
       "   'token': 823,\n",
       "   'token_str': 'dysfunction',\n",
       "   'sequence': '[CLS] polyneuropathy of other causes, including but not limited to[MASK] demyelinating neuropathies,[MASK] secondary to infection or systemic[MASK], diabetic neuropathy, drug- or toxin-induced neuropathies, multifocal motor dysfunction, monoclonal gammopathy of uncertain significance, lumbosacral radiculoplexus neuropathy, pure sensory cidp and acquired demyelinating symmetric (dads) neuropathy (also known as distal cidp).[SEP]'},\n",
       "  {'score': 0.03380608558654785,\n",
       "   'token': 516,\n",
       "   'token_str': 'disorders',\n",
       "   'sequence': '[CLS] polyneuropathy of other causes, including but not limited to[MASK] demyelinating neuropathies,[MASK] secondary to infection or systemic[MASK], diabetic neuropathy, drug- or toxin-induced neuropathies, multifocal motor disorders, monoclonal gammopathy of uncertain significance, lumbosacral radiculoplexus neuropathy, pure sensory cidp and acquired demyelinating symmetric (dads) neuropathy (also known as distal cidp).[SEP]'},\n",
       "  {'score': 0.032239969819784164,\n",
       "   'token': 10,\n",
       "   'token_str': ',',\n",
       "   'sequence': '[CLS] polyneuropathy of other causes, including but not limited to[MASK] demyelinating neuropathies,[MASK] secondary to infection or systemic[MASK], diabetic neuropathy, drug- or toxin-induced neuropathies, multifocal motor,, monoclonal gammopathy of uncertain significance, lumbosacral radiculoplexus neuropathy, pure sensory cidp and acquired demyelinating symmetric (dads) neuropathy (also known as distal cidp).[SEP]'},\n",
       "  {'score': 0.026626363396644592,\n",
       "   'token': 2465,\n",
       "   'token_str': 'neuropathy',\n",
       "   'sequence': '[CLS] polyneuropathy of other causes, including but not limited to[MASK] demyelinating neuropathies,[MASK] secondary to infection or systemic[MASK], diabetic neuropathy, drug- or toxin-induced neuropathies, multifocal motor neuropathy, monoclonal gammopathy of uncertain significance, lumbosacral radiculoplexus neuropathy, pure sensory cidp and acquired demyelinating symmetric (dads) neuropathy (also known as distal cidp).[SEP]'}]]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = 'Polyneuropathy of other causes, including but not limited to hereditary demyelinating neuropathies, neuropathies secondary to infection or systemic disease, diabetic neuropathy, drug- or toxin-induced neuropathies, multifocal motor neuropathy, monoclonal gammopathy of uncertain significance, lumbosacral radiculoplexus neuropathy, pure sensory CIDP and acquired demyelinating symmetric (DADS) neuropathy (also known as distal CIDP).'\n",
    "sent = f'Polyneuropathy of other causes, including but not limited to {mlm.tokenizer.mask_token} demyelinating neuropathies,  {mlm.tokenizer.mask_token} secondary to infection or systemic {mlm.tokenizer.mask_token}, diabetic neuropathy, drug- or toxin-induced neuropathies, multifocal motor {mlm.tokenizer.mask_token}, monoclonal gammopathy of uncertain significance, lumbosacral radiculoplexus neuropathy, pure sensory CIDP and acquired demyelinating symmetric (DADS) neuropathy (also known as distal CIDP).'\n",
    "mlm(sent, top_k = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Table of content](#TOC)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Token Classification",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
